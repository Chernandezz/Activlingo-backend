# ai/analyzer_agent.py - BASIC ANALYZER SÃšPER PODEROSO

from langchain_core.messages import SystemMessage, AIMessage, HumanMessage
from langchain_openai import ChatOpenAI
from typing import Dict, List
import json
import time

analyzer_model = ChatOpenAI(model="gpt-4o")

def detect_speech_transcription(text: str) -> bool:
    """Detecta si el texto parece provenir de speech-to-text"""
    if not text:
        return False
        
    indicators = [
        len(text.split()) > 10 and text.count('.') == 0,
        text.count(',') == 0 and len(text.split()) > 5,
        not text[0].isupper(),
        '?' not in text and any(word in text.lower() for word in ['what', 'how', 'when', 'where', 'why'])
    ]
    detected = sum(indicators) >= 2
    print(f"ğŸ”§ [POWERFUL] Speech transcription: {detected} ({sum(indicators)}/4 indicators)")
    return detected

def filter_transcription_errors(feedback_list: List[Dict], is_transcribed: bool) -> List[Dict]:
    """Filtra errores irrelevantes para conversaciÃ³n oral"""
    if not is_transcribed:
        return feedback_list
    
    irrelevant_keywords = [
        "coma", "comma", "punto", "period", "mayÃºscula", "capital", 
        "signo de interrogaciÃ³n", "question mark", "puntuaciÃ³n", "punctuation"
    ]
    
    filtered = []
    for item in feedback_list:
        explanation = item.get("explanation", "").lower()
        if not any(keyword in explanation for keyword in irrelevant_keywords):
            filtered.append(item)
        else:
            print(f"ğŸ”§ [POWERFUL] Filtered punctuation error: {item.get('category')}")
    
    return filtered

def categorize_feedback_by_severity(feedback_list: List[Dict]) -> Dict[str, List[Dict]]:
    """Organiza feedback por severidad con reglas inteligentes"""
    
    categorized = {"high": [], "medium": [], "low": []}
    
    # Reglas de severidad inteligentes
    severity_rules = {
        "grammar": "high",                  # Tiempos verbales, concordancia
        "vocabulary": "high",               # Palabras incorrectas
        "context_appropriateness": "medium", # Registro formal/informal
        "collocation": "medium",            # Combinaciones naturales
        "phrasal_verb": "medium",           # Verbos compuestos
        "expression": "low"                 # Fluidez general
    }
    
    for item in feedback_list:
        category = item.get("category", "unknown")
        
        # Usar severidad del modelo si existe, sino aplicar reglas
        severity = item.get("severity", severity_rules.get(category, "medium"))
        item["severity"] = severity
        
        # Normalizar formato y usar learning_tip del modelo
        if "original" not in item:
            item["original"] = item.get("mistake", "")
        if "corrected" not in item:
            item["corrected"] = item.get("suggestion", "")
        if "issue_type" not in item:
            item["issue_type"] = item.get("issue", f"{category}_error")
        
        # ğŸ¯ USAR LEARNING TIP DEL MODELO (no hardcoded)
        if "learning_tip" not in item or not item["learning_tip"]:
            # Fallback simple si el modelo no generÃ³ learning_tip
            item["learning_tip"] = f"ğŸ’¡ Practica mÃ¡s {category} para mejorar tu fluidez"
        
        if "examples" not in item:
            item["examples"] = [item.get("suggestion", "")]
        
        categorized[severity].append(item)
    
    print(f"ğŸ”§ [POWERFUL] Severity: high={len(categorized['high'])}, medium={len(categorized['medium'])}, low={len(categorized['low'])}")
    return categorized

def generate_summary(prioritized_feedback: Dict[str, List[Dict]]) -> str:
    """Genera resumen inteligente del anÃ¡lisis"""
    
    high_count = len(prioritized_feedback["high"])
    medium_count = len(prioritized_feedback["medium"])
    low_count = len(prioritized_feedback["low"])
    
    if high_count == 0 and medium_count == 0 and low_count == 0:
        return "Â¡Excelente! Tu inglÃ©s suena muy natural ğŸ‰"
    elif high_count == 0 and medium_count == 0:
        return f"Â¡Muy bien! Solo {low_count} sugerencia(s) de estilo ğŸ‘"
    elif high_count == 0:
        return f"Â¡Bien! {medium_count} sugerencia(s) para sonar mÃ¡s natural ğŸ“ˆ"
    elif high_count == 1:
        return "Una correcciÃ³n importante y algunas sugerencias opcionales ğŸ“"
    else:
        return f"{high_count} correcciones importantes para mejorar la comunicaciÃ³n ğŸ¯"

# ğŸš€ PROMPT SÃšPER PODEROSO PERO COMPACTO - MEJORADO
def create_powerful_prompt() -> str:
    return """You are an expert English conversation coach. Analyze the learner's message for ALL types of spoken English errors.

ğŸ¯ CRITICAL: Detect errors across ALL categories, not just expressions!

âŒ IGNORE: punctuation, capitalization, obvious transcription errors
âœ… ANALYZE: Check EVERY category systematically

ğŸ“‹ CATEGORIES (check ALL of these):

ğŸ”´ "grammar" - PRIORITY CHECK:
- Wrong verb tenses (I go yesterday â†’ I went yesterday)
- Subject-verb disagreement (She don't â†’ She doesn't)  
- Missing/wrong articles (go to store â†’ go to the store)
- Wrong prepositions (good in math â†’ good at math)

ğŸŸ  "vocabulary" - PRIORITY CHECK:
- Non-existent words (mentality â†’ temperament)
- Wrong word choice (realize vs notice)
- False friends from Spanish

ğŸ”µ "phrasal_verb" - PRIORITY CHECK:
- Missing phrasal verbs (I woke at 7am â†’ I woke up at 7am)
- Wrong phrasal verbs (take of â†’ take off)
- Opportunities for natural phrasal verbs

ğŸŸ¢ "collocation" - PRIORITY CHECK:
- Wrong verb-noun combinations (do a decision â†’ make a decision)
- Unnatural word pairs (strong tea â†’ strong coffee, heavy rain)
- Preposition collocations (different of â†’ different from)

ğŸŸ£ "context_appropriateness" - PRIORITY CHECK:
- Too formal for casual context (I would like to request â†’ Can I have)
- Too informal for formal context (Hey dude â†’ Hello sir)

ğŸŸ¡ "expression" - LAST CHECK:
- Only after checking all above categories
- Unnatural phrases that don't fit other categories

ğŸ” ANALYSIS PROCESS:
1. Check grammar errors first (tenses, articles, agreement)
2. Check vocabulary (wrong individual words)
3. Check collocations (word combinations)
4. Check phrasal verbs (compound verbs)
5. Check context appropriateness (formality)
6. Finally check expressions (general fluency)

âš¡ RULES:
- Max 4 suggestions total
- Must check ALL categories systematically  
- Don't default to "expression" - be specific!
- Explanations in Spanish
- Include helpful learning tip for each error

ğŸ¯ OUTPUT: JSON array with learning_tip field. If perfect, return []

EXAMPLE showing category diversity:
[
  {
    "category": "grammar",
    "mistake": "I go to store yesterday",
    "suggestion": "I went to the store yesterday", 
    "explanation": "Usa pasado simple 'went' para acciones terminadas. TambiÃ©n necesitas el artÃ­culo 'the' antes de 'store'.",
    "learning_tip": "ğŸ• Regla: Para pasado simple, agrega -ed a verbos regulares (walk â†’ walked). Para 'go' es irregular: go â†’ went",
    "issue": "past_tense_and_article_error"
  },
  {
    "category": "collocation", 
    "mistake": "make homework",
    "suggestion": "do homework",
    "explanation": "Se dice 'do homework', no 'make homework'. Es una colocaciÃ³n fija en inglÃ©s.",
    "learning_tip": "ğŸ¯ Truco: MAKE = crear algo nuevo (make a cake). DO = actividades/tareas (do homework, do exercise)",
    "issue": "verb_noun_collocation"
  },
  {
    "category": "vocabulary",
    "mistake": "good mentality",
    "suggestion": "good temperament", 
    "explanation": "'Mentality' no se usa asÃ­ en inglÃ©s. 'Temperament' es mejor para personalidad.",
    "learning_tip": "ğŸ§  Memoria: Temperament = carÃ¡cter natural de una persona. Mentality = forma de pensar grupal",
    "issue": "wrong_word_choice"
  }
]

ğŸ“ LEARNING TIP GUIDELINES:
- Start with emoji (ğŸ•ğŸ“ğŸ¯ğŸ§ ğŸ’¡ğŸ”—âš¡)
- Give practical rules or memory tricks
- Keep it short and actionable
- Make it different from the explanation
- Focus on "how to remember" or "quick rule"

âš ï¸ IMPORTANT: Don't classify everything as "expression" - be precise with categories!"""

def analyze_message(ai_text: str, user_text: str) -> str:
    """Analiza mensaje con prompt sÃºper poderoso"""
    print(f"ğŸ”§ [POWERFUL] Analyzing: '{user_text[:60]}{'...' if len(user_text) > 60 else ''}'")
    
    messages = [
        SystemMessage(content=create_powerful_prompt()),
        AIMessage(content=ai_text),
        HumanMessage(content=user_text)
    ]

    try:
        start_time = time.time()
        result = analyzer_model.invoke(messages)
        execution_time = time.time() - start_time
        
        print(f"ğŸ”§ [POWERFUL] Response in {execution_time:.2f}s")
        print(f"ğŸ”§ [POWERFUL] Raw: {result.content[:150]}...")
        
        return result.content
    except Exception as e:
        print(f"ğŸ”§ [POWERFUL] âŒ Error: {e}")
        return "[]"

def deduplicate_suggestions(feedback_list: List[Dict]) -> List[Dict]:
    """Elimina sugerencias duplicadas o muy similares"""
    if len(feedback_list) <= 1:
        return feedback_list
    
    deduplicated = []
    seen_mistakes = set()
    
    for item in feedback_list:
        mistake_key = item.get('mistake', '').lower().strip()
        
        # Si ya vimos un error muy similar, saltar
        if any(abs(len(mistake_key) - len(seen)) < 3 and 
               mistake_key in seen or seen in mistake_key 
               for seen in seen_mistakes):
            print(f"ğŸ”§ [POWERFUL] Skipped duplicate: {mistake_key}")
            continue
        
        seen_mistakes.add(mistake_key)
        deduplicated.append(item)
    
    print(f"ğŸ”§ [POWERFUL] Deduplicated: {len(feedback_list)} â†’ {len(deduplicated)}")
    return deduplicated

def prioritize_by_impact(feedback_list: List[Dict]) -> List[Dict]:
    """Prioriza errores por impacto en la comunicaciÃ³n"""
    
    # Palabras clave que indican alto impacto
    high_impact_keywords = [
        "incorrect", "wrong", "doesn't exist", "not a word", 
        "confusing", "unclear", "impedes", "prevents"
    ]
    
    medium_impact_keywords = [
        "unnatural", "better", "more natural", "sounds odd", 
        "unusual", "formal", "informal"
    ]
    
    for item in feedback_list:
        explanation = item.get('explanation', '').lower()
        issue = item.get('issue', '').lower()
        text_to_check = f"{explanation} {issue}"
        
        # Asignar prioridad basada en contenido
        if any(keyword in text_to_check for keyword in high_impact_keywords):
            item['priority'] = 1  # Alta
        elif any(keyword in text_to_check for keyword in medium_impact_keywords):
            item['priority'] = 2  # Media
        else:
            item['priority'] = 3  # Baja
    
    # Ordenar por prioridad
    sorted_feedback = sorted(feedback_list, key=lambda x: x.get('priority', 3))
    
    if sorted_feedback:
        print(f"ğŸ”§ [POWERFUL] Prioritized by impact: {[item.get('priority', 3) for item in sorted_feedback[:3]]}")
    
    return sorted_feedback

def basic_analysis(ai_text: str, user_text: str) -> Dict:
    """
    ğŸš€ ANÃLISIS BÃSICO SÃšPER PODEROSO
    """
    print(f"ğŸ”§ [POWERFUL] === STARTING POWERFUL BASIC ANALYSIS ===")
    
    # Detectar transcripciÃ³n de voz
    seems_transcribed = detect_speech_transcription(user_text)
    
    # Obtener anÃ¡lisis poderoso
    print(f"ğŸ”§ [POWERFUL] Sending to powerful model...")
    raw_response = analyze_message(ai_text, user_text)
    
    try:
        # Parsear respuesta
        raw_feedback = json.loads(raw_response)
        if not isinstance(raw_feedback, list):
            print(f"ğŸ”§ [POWERFUL] âš ï¸ Non-list response, converting")
            raw_feedback = []
        print(f"ğŸ”§ [POWERFUL] Parsed {len(raw_feedback)} suggestions")
    except Exception as e:
        print(f"ğŸ”§ [POWERFUL] âŒ JSON error: {e}")
        raw_feedback = []
    
    # Mostrar sugerencias encontradas
    if raw_feedback:
        print(f"ğŸ”§ [POWERFUL] Found suggestions:")
        for i, item in enumerate(raw_feedback, 1):
            cat = item.get('category', 'N/A')
            mistake = item.get('mistake', 'N/A')[:40]
            suggestion = item.get('suggestion', 'N/A')[:40]
            print(f"ğŸ”§ [POWERFUL]   [{i}] {cat}: '{mistake}' â†’ '{suggestion}'")
    
    # ğŸ”§ Filtrar errores de transcripciÃ³n
    filtered_feedback = filter_transcription_errors(raw_feedback, seems_transcribed)
    
    # ğŸ¯ Deduplicar sugerencias similares
    deduplicated_feedback = deduplicate_suggestions(filtered_feedback)
    
    # ğŸ“Š Priorizar por impacto
    prioritized_raw = prioritize_by_impact(deduplicated_feedback)
    
    # ğŸ“‹ Categorizar por severidad
    prioritized = categorize_feedback_by_severity(prioritized_raw)
    
    # ğŸ¯ Limitar a las mÃ¡s importantes (inteligentemente)
    if seems_transcribed:
        max_suggestions = 2  # Menos sugerencias para voz
    else:
        max_suggestions = 4  # MÃ¡s para texto escrito
    
    # Priorizar: high â†’ medium â†’ low
    final_feedback = (prioritized["high"] + prioritized["medium"] + prioritized["low"])[:max_suggestions]
    
    print(f"ğŸ”§ [POWERFUL] Final: {len(final_feedback)} suggestions (max: {max_suggestions})")
    
    # Mostrar sugerencias finales
    if final_feedback:
        print(f"ğŸ”§ [POWERFUL] Final suggestions:")
        for i, item in enumerate(final_feedback, 1):
            print(f"ğŸ”§ [POWERFUL]   [{i}] {item.get('category')}: {item.get('mistake', '')[:30]} â†’ {item.get('suggestion', '')[:30]}")
    
    # Generar resumen
    summary = generate_summary(prioritized)
    
    result = {
        "feedback": final_feedback,
        "prioritized": prioritized,
        "is_transcribed": seems_transcribed,
        "total_issues": len(filtered_feedback),
        "summary": summary,
        "plan_type": "basic_powerful"
    }
    
    print(f"ğŸ”§ [POWERFUL] === POWERFUL ANALYSIS COMPLETE ===")
    return result